{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dt1 = pd.read_csv('./Dataset-ThayDau/FFmpeg_full.csv')\n",
    "dt2 = pd.read_csv('./Dataset-ThayDau/LibPNG_full.csv')\n",
    "dt3 = pd.read_csv('./Dataset-ThayDau/LibTIFF_full.csv')\n",
    "dt4 = pd.read_csv('./Dataset-ThayDau/VLC_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5765, 2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(621, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(827, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6362, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200050, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt5 = pd.read_csv('./Dataset-ChiThuy-Sy/juliet_dataset.csv')\n",
    "dt5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200050, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = pd.concat([dt1, dt2, dt3, dt4])\n",
    "data = dt5\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lọc các giá trị Null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200050 entries, 0 to 200049\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   code    200050 non-null  object\n",
      " 1   label   200050 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200050 entries, 0 to 200049\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   code    200050 non-null  object\n",
      " 1   label   200050 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Loại bỏ các dòng có giá trị null trong cột 'code'\n",
    "data.dropna(subset=['code'], inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lọc các trường hợp bị trùng nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28900"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171150, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(171150, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt0 = data\n",
    "dt0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dt0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phân phối của dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "colors = sns.color_palette('muted')\n",
    "val = data['label'].value_counts().values\n",
    "ind = data['label'].value_counts().index\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.pie(val, labels=ind, autopct='%1.1f%%', startangle=140, colors=colors)\n",
    "plt.title(f'Distribution of Safety Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kế thừa các tham số từ mô hình CodeBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: './codebert'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\SyLV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:402\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 402\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\SyLV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[1;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\SyLV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m--> 106\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SyLV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\huggingface_hub\\utils\\_validators.py:160\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[1;34m(repo_id)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[0;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must use alphanumeric chars or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m are\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m forbidden, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m cannot start or end the name, max length is 96:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    163\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    164\u001b[0m     )\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m..\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m repo_id:\n",
      "\u001b[1;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './codebert'.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01moptim\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RobertaTokenizer, RobertaModel\n\u001b[1;32m----> 7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mRobertaTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./codebert\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m RobertaModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./codebert\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\SyLV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:2190\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtokenizer_file\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m vocab_files:\n\u001b[0;32m   2188\u001b[0m     \u001b[38;5;66;03m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[39;00m\n\u001b[0;32m   2189\u001b[0m     fast_tokenizer_file \u001b[38;5;241m=\u001b[39m FULL_TOKENIZER_FILE\n\u001b[1;32m-> 2190\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2191\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2192\u001b[0m \u001b[43m        \u001b[49m\u001b[43mTOKENIZER_CONFIG_FILE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2200\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2201\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2202\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2203\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2204\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2205\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2206\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2207\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m   2208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\SyLV\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:466\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 466\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    467\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    468\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    469\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
      "\u001b[1;31mOSError\u001b[0m: Incorrect path_or_model_id: './codebert'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"./codebert\")\n",
    "model = RobertaModel.from_pretrained(\"./codebert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thêm các lớp phân loại"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CodeVulnerabilityClassifier(nn.Module):\n",
    "    def __init__(self, codebert_model):\n",
    "        super(CodeVulnerabilityClassifier, self).__init__()\n",
    "        self.codebert = codebert_model\n",
    "        # for param in self.codebert.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        self.fc1 = nn.Linear(768, 512)  \n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.codebert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        pooled_output = outputs[1]  \n",
    "        out1 = F.relu(self.fc1(pooled_output)) \n",
    "        out2 = F.relu(self.fc2(out1))  \n",
    "        logits = self.fc3(out2)  \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xử lý dữ liệu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia tập dữ liệu thành tập train và tập test (giả sử data là dataframe chứa 'code' và 'safety' fields)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tiền xử lý dữ liệu và chuyển đổi thành dạng tensor sử dụng tokenizer\n",
    "train_texts = train_data['code'].tolist()\n",
    "for i in range(len(train_texts)):\n",
    "    if not isinstance(train_texts[i], str):\n",
    "        print(train_texts[i])\n",
    "        train_texts[i] = str(train_texts[i])\n",
    "train_labels = train_data['label'].tolist()\n",
    "\n",
    "test_texts = test_data['code'].tolist()\n",
    "for i in range(len(test_texts)):\n",
    "    if not isinstance(test_texts[i], str):\n",
    "        print(train_texts[i])\n",
    "        test_texts[i] = str(test_texts[i])\n",
    "test_labels = test_data['label'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Encoding dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=256, return_tensors='pt')\n",
    "\n",
    "train_dataset = torch.utils.data.TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], torch.tensor(train_labels))\n",
    "test_dataset = torch.utils.data.TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], torch.tensor(test_labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chọn bộ tối ưu, hàm mất mát, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "learning_rate = 1e-4\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "classifier = CodeVulnerabilityClassifier(model)\n",
    "classifier.to(device)\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f77cf69b7d4c0cbe0322a543b6c496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7000, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6988, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6911, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6835, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.6086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5769, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5088, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4182, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.5280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4938, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4972, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4308, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4299, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3845, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3361, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3039, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3156, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2399, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2898, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3539, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2821, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2505, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3608, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2874, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2587, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2386, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2630, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3059, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2805, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1885, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2723, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1836, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1605, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2790, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1779, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2007, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1993, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1995, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2242, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1996, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2310, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2143, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2134, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2558, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1834, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2740, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2146, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2107, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2870, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2302, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1821, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2457, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1952, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1479, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2149, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2032, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2175, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2024, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1970, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2649, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1914, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2144, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2207, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1819, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1588, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2962, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2804, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2450, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2418, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1623, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1883, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2785, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1506, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2480, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2161, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1682, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2136, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1923, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1995, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1815, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1362, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1818, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1873, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2079, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1890, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1876, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1581, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1772, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1890, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1801, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1623, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1533, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2073, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1969, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1958, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1962, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2029, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1985, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1982, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2354, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2038, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1984, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2080, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2306, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2011, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2065, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2045, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1871, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2747, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1212, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1827, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2090, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2034, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1643, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1336, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1965, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1935, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2300, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1904, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1417, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1676, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1804, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1963, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2151, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1830, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2647, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2546, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2232, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2204, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1910, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1496, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1961, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1637, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1211, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1897, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2108, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2191, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1788, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1631, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2025, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1778, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2085, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1735, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1847, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2086, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1669, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1733, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1982, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1678, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2026, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1635, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1683, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.4917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2444, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2824, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2206, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2119, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2887, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2010, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2122, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2277, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1892, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2215, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1432, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2461, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1356, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1398, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1577, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2225, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1521, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1936, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2002, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1643, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2282, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1664, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2043, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1421, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1933, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1969, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1993, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1864, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2041, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1503, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1801, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1529, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2589, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2476, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2469, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2557, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2550, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2309, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2390, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2408, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2056, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2665, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.3353, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1820, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2237, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2452, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1859, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2271, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2355, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1902, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1908, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2335, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2269, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2584, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2650, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2060, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1803, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2046, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1674, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1694, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1780, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1730, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2183, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1658, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1827, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1745, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1739, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1600, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1536, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1973, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2036, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1977, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1424, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1994, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2113, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1922, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1953, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2068, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1856, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2197, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1861, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2194, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1843, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1718, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2301, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2071, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1341, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1434, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2051, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1660, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1664, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1783, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1746, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2142, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1628, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2708, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1538, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1256, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1928, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1517, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1941, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1390, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1786, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1507, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1966, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1789, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1953, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2393, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1561, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1692, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1865, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1893, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2047, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1840, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1525, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2451, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1863, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1371, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2031, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1910, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1774, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1917, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1426, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1904, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1948, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1759, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1322, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1743, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1497, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1625, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1863, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1870, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1732, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1905, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2013, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1527, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1915, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2224, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2018, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1775, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1955, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2132, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2005, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1693, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1721, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1541, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2217, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1900, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1768, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1576, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2198, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1169, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1994, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1701, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1693, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1909, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2200, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1750, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1960, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1563, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1884, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2230, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1967, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1782, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1188, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1234, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1654, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2109, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1427, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1583, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1677, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1442, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1262, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2172, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1903, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2121, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2054, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2100, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1783, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1578, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2027, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1906, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1896, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1794, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1422, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2179, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1409, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1920, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2280, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1823, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1395, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1992, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1843, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1376, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1799, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1911, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1241, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1729, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1208, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1425, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1187, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2244, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1642, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1921, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1651, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1776, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2396, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1973, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1665, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1824, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1972, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0996, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1261, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1532, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2498, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2528, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0935, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2185, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1621, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1760, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1644, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1770, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1930, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1360, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1943, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1868, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1436, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1952, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1881, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1474, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1858, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1736, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1611, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1357, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1253, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1228, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1619, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1802, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1596, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1330, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1460, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1510, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2220, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1487, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1751, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2055, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1742, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2015, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1449, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1787, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2114, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2538, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1877, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1811, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1350, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1895, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1164, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2272, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1814, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1544, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1984, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2231, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1686, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1755, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1404, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1841, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1620, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1726, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1907, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2052, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1866, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1934, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2070, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1995, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2127, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1679, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2213, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1454, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1287, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1522, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1572, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1689, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2123, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1690, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2229, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2131, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1632, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1472, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1515, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1582, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1344, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1616, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1719, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1835, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1648, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1675, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0964, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1255, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1513, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2323, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1940, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2660, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1773, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2374, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1837, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1606, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2050, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2009, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1292, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1670, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1693, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1602, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1249, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1512, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2295, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1551, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1756, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1884, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1379, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1705, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2378, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0982, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1731, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1492, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1592, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1649, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1618, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1782, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1564, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2097, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1392, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1988, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1793, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1486, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1782, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1585, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1717, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1962, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1468, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1519, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1710, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2312, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1607, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1471, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1696, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1702, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1744, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1738, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1932, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1797, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2087, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1971, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1662, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1414, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1767, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1385, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2003, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1732, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0957, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1968, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2174, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2258, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1475, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1714, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1899, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1627, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1624, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1062, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1495, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1343, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1482, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2004, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2189, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1700, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1601, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1448, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1236, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1655, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1666, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1681, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1440, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1816, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1072, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1636, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1892, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1810, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1324, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1435, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1403, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0931, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1883, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1706, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1140, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1401, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1754, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1574, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1008, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1166, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2192, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1331, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1326, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1465, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1264, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2138, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1911, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1603, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1369, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1807, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1158, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1431, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1562, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2318, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1610, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1904, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1753, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1481, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1383, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1467, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1661, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1808, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1918, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1289, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1795, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1470, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1278, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1391, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1853, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1311, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1913, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2163, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2193, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1673, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1930, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2210, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1956, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1688, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1663, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1290, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1855, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1458, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1548, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2195, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1825, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1388, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2061, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2094, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1488, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1445, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1501, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1698, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1505, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2124, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1411, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1609, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1872, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1626, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1842, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2327, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1382, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1815, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2259, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1662, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1571, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1828, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1667, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1570, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1514, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1437, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1540, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1972, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2126, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1573, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1494, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1293, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1974, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1430, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1645, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1926, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2177, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1711, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1477, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1485, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1829, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2078, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1478, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1848, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1084, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2058, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1884, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2504, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1227, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1849, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2069, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1568, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1882, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1844, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1904, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1291, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1886, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1534, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1555, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1734, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1110, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1346, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1657, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1303, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1946, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0875, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1446, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1704, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1668, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1569, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1439, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1560, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2098, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1462, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2357, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1252, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1420, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1338, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2067, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2066, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1787, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1505, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1634, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1832, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2266, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1716, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1263, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1381, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1833, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1333, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1239, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1925, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1927, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1455, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1954, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1285, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1595, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1370, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1152, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1749, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1531, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1684, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2111, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1245, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1638, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1351, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1867, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1304, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1489, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1433, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1345, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.2123, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "for epoch in tqdm(range(1), total=1):\n",
    "    for input_ids, attention_mask, labels in train_loader:\n",
    "        input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        logits = classifier(input_ids, attention_mask)\n",
    "        loss = loss_fn(logits, labels)\n",
    "        # loss = loss_fn(threads, labels)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.4 Accuracy: 0.8927548933683903\n",
      "Threshold: 0.5 Accuracy: 0.8972246567338592\n",
      "Threshold: 0.6 Accuracy: 0.8949751679813029\n"
     ]
    }
   ],
   "source": [
    "# Đánh giá mô hình trên tập test\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "threshold = 0.4\n",
    "\n",
    "while(threshold<=0.6):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, labels in test_loader:\n",
    "            input_ids, attention_mask, labels = input_ids.to(device), attention_mask.to(device), labels.to(device)\n",
    "            \n",
    "            logits = classifier(input_ids, attention_mask)\n",
    "\n",
    "            probs = torch.nn.functional.softmax(logits, dim=1)  # Chuyển đổi logits thành xác suất\n",
    "            predictions = (probs[:, 1] > threshold).long()  # Sử dụng ngưỡng quyết định\n",
    "            total += labels.size(0)\n",
    "            correct += (predictions == labels).sum().item()\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    print(f'Threshold: {threshold} Accuracy: {accuracy}')\n",
    "    threshold += 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lưu mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./model_test\\\\tokenizer_config.json',\n",
       " './model_test\\\\special_tokens_map.json',\n",
       " './model_test\\\\vocab.json',\n",
       " './model_test\\\\merges.txt',\n",
       " './model_test\\\\added_tokens.json')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trước khi lưu hãy đặt tên lại cho folder đích theo cấu hình của model \n",
    "# Đặt tên theo quy tắc: model_số layer_bộ tối ưu_learning rate_accuracy\n",
    "\n",
    "model.save_pretrained('./model_test')\n",
    "tokenizer.save_pretrained('./model_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict': classifier.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss':loss.item(),\n",
    "            },'h.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
